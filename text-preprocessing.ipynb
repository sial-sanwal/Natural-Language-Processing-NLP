{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b06192fa",
   "metadata": {},
   "source": [
    "## Text-preprocessing Basic step\n",
    "- lowercasing\n",
    "- Remove HTML Tags\n",
    "- Remove URLS\n",
    "- Remove Punctutation \n",
    "- Chat word treatment \n",
    "- Spelling Correction\n",
    "- Removing stop word\n",
    "- Handling Emojis \n",
    "- Tokenization \n",
    "- Stemming \n",
    "- Lemmatization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "322dd384",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "364f96df",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"IMDB Dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "202aeba6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7bcb3f04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d0c031",
   "metadata": {},
   "source": [
    "# lowercasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e87199e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Basically there's a family where a little boy (Jake) thinks there's a zombie in his closet & his parents are fighting all the time.<br /><br />This movie is slower than a soap opera... and suddenly, Jake decides to become Rambo and kill the zombie.<br /><br />OK, first of all when you're going to make a film you must Decide if its a thriller or a drama! As a drama the movie is watchable. Parents are divorcing & arguing like in real life. And then we have Jake with his closet which totally ruins all the film! I expected to see a BOOGEYMAN similar movie, and instead i watched a drama with some meaningless thriller spots.<br /><br />3 out of 10 just for the well playing parents & descent dialogs. As for the shots with Jake: just ignore them.\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"review\"][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5f71ce1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"basically there's a family where a little boy (jake) thinks there's a zombie in his closet & his parents are fighting all the time.<br /><br />this movie is slower than a soap opera... and suddenly, jake decides to become rambo and kill the zombie.<br /><br />ok, first of all when you're going to make a film you must decide if its a thriller or a drama! as a drama the movie is watchable. parents are divorcing & arguing like in real life. and then we have jake with his closet which totally ruins all the film! i expected to see a boogeyman similar movie, and instead i watched a drama with some meaningless thriller spots.<br /><br />3 out of 10 just for the well playing parents & descent dialogs. as for the shots with jake: just ignore them.\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"review\"][3].lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5627b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"review\"]=df[\"review\"].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "427a7ca0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a wonderful little production. &lt;br /&gt;&lt;br /&gt;the...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petter mattei's \"love in the time of money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>i thought this movie did a down right good job...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>bad plot, bad dialogue, bad acting, idiotic di...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>i am a catholic taught in parochial elementary...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>i'm going to have to disagree with the previou...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>no one expects the star trek movies to be high...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment\n",
       "0      one of the other reviewers has mentioned that ...  positive\n",
       "1      a wonderful little production. <br /><br />the...  positive\n",
       "2      i thought this was a wonderful way to spend ti...  positive\n",
       "3      basically there's a family where a little boy ...  negative\n",
       "4      petter mattei's \"love in the time of money\" is...  positive\n",
       "...                                                  ...       ...\n",
       "49995  i thought this movie did a down right good job...  positive\n",
       "49996  bad plot, bad dialogue, bad acting, idiotic di...  negative\n",
       "49997  i am a catholic taught in parochial elementary...  negative\n",
       "49998  i'm going to have to disagree with the previou...  negative\n",
       "49999  no one expects the star trek movies to be high...  negative\n",
       "\n",
       "[50000 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd12c52",
   "metadata": {},
   "source": [
    "# Remove HTML Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "48be46bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"basically there's a family where a little boy (jake) thinks there's a zombie in his closet & his parents are fighting all the time.<br /><br />this movie is slower than a soap opera... and suddenly, jake decides to become rambo and kill the zombie.<br /><br />ok, first of all when you're going to make a film you must decide if its a thriller or a drama! as a drama the movie is watchable. parents are divorcing & arguing like in real life. and then we have jake with his closet which totally ruins all the film! i expected to see a boogeyman similar movie, and instead i watched a drama with some meaningless thriller spots.<br /><br />3 out of 10 just for the well playing parents & descent dialogs. as for the shots with jake: just ignore them.\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"review\"][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "13ee1c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def remove_html_tags(text):\n",
    "    pattern=re.compile('<.*?>')\n",
    "    return pattern.sub(r'',text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e6ba8b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "text=\"basically there's a family where a little boy (jake) thinks there's a zombie in his closet & his parents are fighting all the time.<br /><br />this movie is slower than a soap opera... and suddenly, jake decides to become rambo and kill the zombie.<br /><br />ok, first of all when you're going to make a film you must decide if its a thriller or a drama! as a drama the movie is watchable. parents are divorcing & arguing like in real life. and then we have jake with his closet which totally ruins all the film! i expected to see a boogeyman similar movie, and instead i watched a drama with some meaningless thriller spots.<br /><br />3 out of 10 just for the well playing parents & descent dialogs. as for the shots with jake: just ignore them.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "31d1382b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"basically there's a family where a little boy (jake) thinks there's a zombie in his closet & his parents are fighting all the time.<br /><br />this movie is slower than a soap opera... and suddenly, jake decides to become rambo and kill the zombie.<br /><br />ok, first of all when you're going to make a film you must decide if its a thriller or a drama! as a drama the movie is watchable. parents are divorcing & arguing like in real life. and then we have jake with his closet which totally ruins all the film! i expected to see a boogeyman similar movie, and instead i watched a drama with some meaningless thriller spots.<br /><br />3 out of 10 just for the well playing parents & descent dialogs. as for the shots with jake: just ignore them.\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8ff7e14c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"basically there's a family where a little boy (jake) thinks there's a zombie in his closet & his parents are fighting all the time.this movie is slower than a soap opera... and suddenly, jake decides to become rambo and kill the zombie.ok, first of all when you're going to make a film you must decide if its a thriller or a drama! as a drama the movie is watchable. parents are divorcing & arguing like in real life. and then we have jake with his closet which totally ruins all the film! i expected to see a boogeyman similar movie, and instead i watched a drama with some meaningless thriller spots.3 out of 10 just for the well playing parents & descent dialogs. as for the shots with jake: just ignore them.\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_html_tags(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d582d89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review']=df['review'].apply(remove_html_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bfc4be84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a wonderful little production. the filming tec...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petter mattei's \"love in the time of money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>i thought this movie did a down right good job...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>bad plot, bad dialogue, bad acting, idiotic di...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>i am a catholic taught in parochial elementary...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>i'm going to have to disagree with the previou...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>no one expects the star trek movies to be high...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment\n",
       "0      one of the other reviewers has mentioned that ...  positive\n",
       "1      a wonderful little production. the filming tec...  positive\n",
       "2      i thought this was a wonderful way to spend ti...  positive\n",
       "3      basically there's a family where a little boy ...  negative\n",
       "4      petter mattei's \"love in the time of money\" is...  positive\n",
       "...                                                  ...       ...\n",
       "49995  i thought this movie did a down right good job...  positive\n",
       "49996  bad plot, bad dialogue, bad acting, idiotic di...  negative\n",
       "49997  i am a catholic taught in parochial elementary...  negative\n",
       "49998  i'm going to have to disagree with the previou...  negative\n",
       "49999  no one expects the star trek movies to be high...  negative\n",
       "\n",
       "[50000 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0907b342",
   "metadata": {},
   "source": [
    "# Removing URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "978240d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "text1=\"for notebook click https:www.kaggle.com/notebook\"\n",
    "text2=\"for notebook click http:www.kaggle.com/notebook\"\n",
    "text3=\"Google Search here www.google.com\"\n",
    "text4=\"for notebook click http:www.kaggle.com/notebook and for google search www.google.com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b5a6f34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_urls(text):\n",
    "    patterns = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return patterns.sub(r'', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eccbdd98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'for notebook click http: and for google search '"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_urls(text4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0e0b92",
   "metadata": {},
   "source": [
    "# Removing Punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9f0824ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "412ad09d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a11a4c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude=string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8388ff1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punc(text):\n",
    "    for char in exclude:\n",
    "        text=text.replace(char,\"\")\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "73856616",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy=\"Hello! I am Sanwal Khan. and I am an AI Enginner!?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e16e3887",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello I am Sanwal Khan and I am an AI Enginner'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_punc(dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6c99d974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello I am Sanwal Khan and I am an AI Enginner\n",
      "0.0029935836791992188\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start=time.time()\n",
    "print(remove_punc(dummy))\n",
    "time1=time.time()-start\n",
    "print(time1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "eabc2c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punc_1(text):\n",
    "    return text.translate(str.maketrans('','',exclude))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b0fd6419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello I am Sanwal Khan and I am an AI Enginner\n",
      "0.0009975433349609375\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start=time.time()\n",
    "print(remove_punc_1(dummy))\n",
    "time2=time.time()-start\n",
    "print(time2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e5f8eca4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0009560229445507"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time1/time2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2769075",
   "metadata": {},
   "source": [
    "# Chat Word Treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fb7040d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "abbreviations_dict = {\n",
    "    'AFAIK': 'As Far As I Know',\n",
    "    'AFK': 'Away From Keyboard',\n",
    "    'ASAP': 'As Soon As Possible',\n",
    "    'ATK': 'At The Keyboard',\n",
    "    'ATM': 'At The Moment',\n",
    "    'A3': 'Anytime, Anywhere, Anyplace',\n",
    "    'BAK': 'Back At Keyboard',\n",
    "    'BBL': 'Be Back Later',\n",
    "    'BBS': 'Be Back Soon',\n",
    "    'BFN': 'Bye For Now',\n",
    "    'B4N': 'Bye For Now',\n",
    "    'BRB': 'Be Right Back',\n",
    "    'BRT': 'Be Right There',\n",
    "    'BTW': 'By The Way',\n",
    "    'B4': 'Before',\n",
    "    'B4N': 'Bye For Now',\n",
    "    'CU': 'See You',\n",
    "    'CUL8R': 'See You Later',\n",
    "    'CYA': 'See You',\n",
    "    'FAQ': 'Frequently Asked Questions',\n",
    "    'FC': 'Fingers Crossed',\n",
    "    'FWIW': 'For What It\\'s Worth',\n",
    "    'FYI': 'For Your Information',\n",
    "    'GAL': 'Get A Life',\n",
    "    'GG': 'Good Game',\n",
    "    'GN': 'Good Night',\n",
    "    'GMTA': 'Great Minds Think Alike',\n",
    "    'GR8': 'Great!',\n",
    "    'G9': 'Genius',\n",
    "    'IC': 'I See',\n",
    "    'ICQ': 'I Seek you (also a chat program)',\n",
    "    'ILU': 'I Love You',\n",
    "    'IMHO': 'In My Honest/Humble Opinion',\n",
    "    'IMO': 'In My Opinion',\n",
    "    'IOW': 'In Other Words',\n",
    "    'IRL': 'In Real Life',\n",
    "    'KISS': 'Keep It Simple, Stupid',\n",
    "    'LDR': 'Long Distance Relationship',\n",
    "    'LMAO': 'Laugh My A.. Off',\n",
    "    'LOL': 'Laughing Out Loud',\n",
    "    'LTNS': 'Long Time No See',\n",
    "    'L8R': 'Later',\n",
    "    'MTE': 'My Thoughts Exactly',\n",
    "    'M8': 'Mate',\n",
    "    'NRN': 'No Reply Necessary',\n",
    "    'OIC': 'Oh I See',\n",
    "    'PITA': 'Pain In The A..',\n",
    "    'PRT': 'Party',\n",
    "    'PRW': 'Parents Are Watching',\n",
    "    'QPSA': 'Que Pasa?',\n",
    "    'ROFL': 'Rolling On The Floor Laughing',\n",
    "    'ROFLOL': 'Rolling On The Floor Laughing Out Loud',\n",
    "    'ROTFLMAO': 'Rolling On The Floor Laughing My A.. Off',\n",
    "    'SK8': 'Skate',\n",
    "    'STATS': 'Your sex and age',\n",
    "    'ASL': 'Age, Sex, Location',\n",
    "    'THX': 'Thank You',\n",
    "    'TTFN': 'Ta-Ta For Now!',\n",
    "    'TTYL': 'Talk To You Later',\n",
    "    'U': 'You',\n",
    "    'U2': 'You Too',\n",
    "    'U4E': 'Yours For Ever',\n",
    "    'WB': 'Welcome Back',\n",
    "    'WTF': 'What The F...',\n",
    "    'WTG': 'Way To Go!',\n",
    "    'WUF': 'Where Are You From?',\n",
    "    'W8': 'Wait...',\n",
    "    '7K': 'Sick:-D Laugher',\n",
    "    'TFW': 'That feeling when',\n",
    "    'MFW': 'My face when',\n",
    "    'MRW': 'My reaction when',\n",
    "    'IFYP': 'I feel your pain',\n",
    "    'LOL': 'Laughing out loud',\n",
    "    'TNTL': 'Trying not to laugh',\n",
    "    'JK': 'Just kidding',\n",
    "    'IDC': 'I don’t care',\n",
    "    'ILY': 'I love you',\n",
    "    'IMU': 'I miss you',\n",
    "    'ADIH': 'Another day in hell',\n",
    "    'IDC': 'I don’t care',\n",
    "    'ZZZ': 'Sleeping, bored, tired',\n",
    "    'WYWH': 'Wish you were here',\n",
    "    'TIME': 'Tears in my eyes',\n",
    "    'BAE': 'Before anyone else',\n",
    "    'FIMH': 'Forever in my heart',\n",
    "    'BSAAW': 'Big smile and a wink',\n",
    "    'BWL': 'Bursting with laughter',\n",
    "    'LMAO': 'Laughing my a** off',\n",
    "    'BFF': 'Best friends forever',\n",
    "    'CSL': 'Can’t stop laughing'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d4fb0db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_conservation(text):\n",
    "    new_text=[]\n",
    "    for w in text.split():\n",
    "        if w.upper() in abbreviations_dict:\n",
    "            new_text.append(abbreviations_dict[w.upper()])\n",
    "        else:\n",
    "            new_text.append(w)\n",
    "    return \" \".join(new_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b1d070bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I See You'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy=\"IC U\"\n",
    "chat_conservation(dummy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f095f8",
   "metadata": {},
   "source": [
    "# Spelling Correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6e4b07a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "30414b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a932d289",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'this is my notebook and the is an other notebook'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incorrect_text=\"this is my notebook and ths is an other notbook\"\n",
    "textblob=TextBlob(incorrect_text)\n",
    "textblob.correct().string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "eded44f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'certain conditions during several ggenratns are modified in the same manner'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incorrect_text=\"ceetrain conditionsa durring seveal ggenratns arre modified in the same maner\"\n",
    "textblob=TextBlob(incorrect_text)\n",
    "textblob.correct().string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c167fcc4",
   "metadata": {},
   "source": [
    "# Removing stop word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6d805956",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "05f80691",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d14d876b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7847a611",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f26d8e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stop_word(text):\n",
    "    new_text=[]\n",
    "    for word in text.split():\n",
    "        if word in stopwords.words(\"english\"):\n",
    "            new_text.append(\"\")\n",
    "        else:\n",
    "            new_text.append(word)\n",
    "    x=new_text[:]\n",
    "    new_text.clear()\n",
    "    return \" \".join(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7d926c79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' name  sanwal khan     AI developer'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy=\"my name is sanwal khan and i am the AI developer\"\n",
    "remove_stop_word(dummy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0632c9b3",
   "metadata": {},
   "source": [
    "# handling Emojo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "55701eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def remove_emoji(text):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                               \"\\U0001F600-\\U0001F64F\"  # Emoticons\n",
    "                               \"\\U0001F300-\\U0001F5FF\"  # Symbols & Pictographs\n",
    "                               \"\\U0001F680-\\U0001F6FF\"  # Transport & Map Symbols\n",
    "                               \"\\U0001F700-\\U0001F77F\"  # Alchemical Symbols\n",
    "                               \"\\U0001F780-\\U0001F7FF\"  # Geometric Shapes Extended\n",
    "                               \"\\U0001F800-\\U0001F8FF\"  # Supplemental Arrows-C\n",
    "                               \"\\U0001F900-\\U0001F9FF\"  # Supplemental Symbols and Pictographs\n",
    "                               \"\\U0001FA00-\\U0001FA6F\"  # Chess Symbols\n",
    "                               \"\\U0001FA70-\\U0001FAFF\"  # Symbols and Pictographs Extended-A\n",
    "                               \"\\U00002702-\\U000027B0\"  # Dingbats\n",
    "                               \"\\U000024C2-\\U0001F251\" \n",
    "                               \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', text)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "134ec7c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello!  How are you today? \n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "text_with_emoji = \"Hello! 😃 How are you today? 🌍\"\n",
    "text_without_emoji = remove_emoji(text_with_emoji)\n",
    "\n",
    "print(text_without_emoji)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "17d206c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "46d6246d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hp machine very :grinning_face_with_big_eyes:\n"
     ]
    }
   ],
   "source": [
    "import emoji\n",
    "print(emoji.demojize(\"Hp machine very 😃\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b846b581",
   "metadata": {},
   "source": [
    "# Tokenization\n",
    "- Tokenization base on two level\n",
    "1. Sentance Level\n",
    "2. Word Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "05316409",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'am', 'going', 'to', 'karachi.']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# word tokenization\n",
    "word=\"I am going to karachi.\"\n",
    "word.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9255ebf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I am going to karachi',\n",
       " ' I am from Faisalabad',\n",
       " ' hope the trip to great',\n",
       " '']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sentence Tokenization\n",
    "sentence=\"I am going to karachi. I am from Faisalabad. hope the trip to great.\"\n",
    "sentence.split(\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "19cacca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'am', 'going', 'to', 'Muree']\n"
     ]
    }
   ],
   "source": [
    "# using regular expression\n",
    "import re\n",
    "\n",
    "sent3 = \"I am going to Muree!\"\n",
    "tokens = re.findall(r'\\w+', sent3)\n",
    "\n",
    "print(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c03bb1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "text=\"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud? exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in! reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est labor\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8f6c9a3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Lorem ipsum dolor sit amet, consectetur adipiscing elit',\n",
       " ' Sed do eiusmod tempor incididunt ut labore et dolore magna aliqua',\n",
       " ' Ut enim ad minim veniam, quis nostrud',\n",
       " ' exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat',\n",
       " ' Duis aute irure dolor in',\n",
       " ' reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur',\n",
       " ' Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est labor']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# on the basic of dot,question makr and extrametely sign\n",
    "re.compile(\"[.?!]\").split(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0682faf0",
   "metadata": {},
   "source": [
    "# using NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3675e365",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\hp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "from nltk.tokenize import word_tokenize,sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5cd7d927",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'am', 'goinf', 'to', 'muree', '!']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sen1=\"I am goinf to muree!\"\n",
    "word_tokenize(sen1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ffeac1f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Lorem ipsum dolor sit amet, consectetur adipiscing elit.',\n",
       " 'Sed do eiusmod tempor incididunt ut labore et dolore magna aliqua.',\n",
       " 'Ut enim ad minim veniam, quis nostrud?',\n",
       " 'exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat.',\n",
       " 'Duis aute irure dolor in!',\n",
       " 'reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur.',\n",
       " 'Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est labor']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text=\"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud? exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in! reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est labor\"\n",
    "sent_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "610ae7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sen5=\"I have a Ph.D in A.I\"\n",
    "sen6=\"we're here to help! mail us at demo@gmail.com\"\n",
    "sen7=\"A 5Km ride cost $10.56\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "76741fc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'have', 'a', 'Ph.D', 'in', 'A.I']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(sen5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b2b51de2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['we',\n",
       " \"'re\",\n",
       " 'here',\n",
       " 'to',\n",
       " 'help',\n",
       " '!',\n",
       " 'mail',\n",
       " 'us',\n",
       " 'at',\n",
       " 'demo',\n",
       " '@',\n",
       " 'gmail.com']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(sen6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "85b7a227",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A', '5Km', 'ride', 'cost', '$', '10.56']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(sen7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a408b53",
   "metadata": {},
   "source": [
    "# Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "76bf7fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install spacy\n",
    "# !python -m spacy download en_core_web_sm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "66e440bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "# Load the English language model\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c0a13a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc1=nlp(sen5)\n",
    "doc2=nlp(sen6)\n",
    "doc3=nlp(sen7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "02f567d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I\n",
      "have\n",
      "a\n",
      "Ph\n",
      ".\n",
      "D\n",
      "in\n",
      "A.I\n"
     ]
    }
   ],
   "source": [
    "for token in doc1:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ed342d73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we\n",
      "'re\n",
      "here\n",
      "to\n",
      "help\n",
      "!\n",
      "mail\n",
      "us\n",
      "at\n",
      "demo@gmail.com\n"
     ]
    }
   ],
   "source": [
    "for token in doc2:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "73698427",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A\n",
      "5Km\n",
      "ride\n",
      "cost\n",
      "$\n",
      "10.56\n"
     ]
    }
   ],
   "source": [
    "for token in doc3:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11a2b7c",
   "metadata": {},
   "source": [
    "# Stemming\n",
    "- converting word into the root form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "16b6a957",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4620ae2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps=PorterStemmer()\n",
    "def stem_words(text):\n",
    "    return \" \".join([ps.stem(words) for words in text.split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "250eaa5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "text=\"walk walks walking walked\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b4896149",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'walk walk walk walk'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stem_words(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9024c9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "text=\"Python is widely used for web development and scripting.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "089e062a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'python is wide use for web develop and scripting.'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stem_words(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b269017",
   "metadata": {},
   "source": [
    "# lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "3846e721",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\hp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "512324a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original        Lemmatized\n",
      "The             The\n",
      "quick           quick\n",
      "brown           brown\n",
      "foxes           fox\n",
      "are             are\n",
      "jumping         jumping\n",
      "over            over\n",
      "the             the\n",
      "lazy            lazy\n",
      "dogs            dog\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Initialize the WordNet lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Sample text\n",
    "text = \"The quick brown foxes are jumping over the lazy dogs\"\n",
    "\n",
    "# Tokenize the text into words\n",
    "words = word_tokenize(text)\n",
    "\n",
    "# Lemmatize each word\n",
    "lemmatized_words = [lemmatizer.lemmatize(word) for word in words]\n",
    "\n",
    "# Print side-by-side comparison\n",
    "print(\"{:<15} {}\".format(\"Original\", \"Lemmatized\"))\n",
    "for original, lemmatized in zip(words, lemmatized_words):\n",
    "    print(\"{:<15} {}\".format(original, lemmatized))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce6151f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285f4ef2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60fad244",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9e1cc3e7",
   "metadata": {},
   "source": [
    "- **Stemming:** Reduces words to their root or base form by removing prefixes or suffixes. The result may not be a valid word.\n",
    "    - Stemming is fast\n",
    "- **Lemmatization:** Reduces words to their base or dictionary form (lemma). The output is a valid word\n",
    "    - Lemmatization is slow due to its find the valid english word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5bfbda6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
